<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "DTD/xhtml1-transitional.dtd">
<html lang="en">
    <head>
<style type="text/css">
.knitr .inline {
  background-color: #f7f7f7;
  border:solid 1px #B0B0B0;
}
.error {
	font-weight: bold;
	color: #FF0000;
}
.warning {
	font-weight: bold;
}
.message {
	font-style: italic;
}
.source, .bigsource, .output, .warning, .error, .message {
	padding: 0 1em;
  border:solid 1px #F7F7F7;
	width:65%;
	margin-left:auto; margin-right:auto;
	border:1px solid #ccc;
	overflow:auto;
	background-color: #FFFFFF;
}
.source {
  background-color: #f5f5f5;
}
.rimage .left {
  text-align: left;
}
.rimage .right {
  text-align: right;
}
.rimage .center {
  text-align: center;
}
.hl.num {
  color: #AF0F91;
}
.hl.str {
  color: #317ECC;
}
.hl.com {
  color: #AD95AF;
  font-style: italic;
}
.hl.opt {
  color: #000000;
}
.hl.std {
  color: #585858;
}
.hl.kwa {
  color: #295F94;
  font-weight: bold;
}
.hl.kwb {
  color: #B05A65;
}
.hl.kwc {
  color: #55aa55;
}
.hl.kwd {
  color: #BC5A65;
  font-weight: bold;
}
</style>
        <meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
        <title>Comparing model coefficients to one another</title>
        <link rel="stylesheet" type="text/css" href="stevetools_stylesheet.css" />
	<script type="text/javascript"
		src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
    <head>

    <body>


		<h2>Comparing linear model coefficients to one another</h2>

		<p class="centercol">There are some situations where you want to compare one regression model coefficient to another, and can't straightforwardly do that by cleverly setting up the right interactions, coding, etc.</p>
		<p class="centercol">For example, say you have lexical decision reaction times (RT) for nouns and verbs, and you also have recorded those words' lengths and frequencies. If you want to know whether frequency has a bigger impact on RTs for nouns than it does for verbs, that's easy: just regress RTs on frequency, word category, and their interaction (<code>RT ~ Frequency*Category</code>) and the interaction will answer your question. But what if you want to know whether frequency has a bigger impact on RT than length does? That's trickier. You can do <code>RT ~ Frequency + Length</code>, pull out standardized coefficients, and see that the effect of Frequency on RT is "this big" whereas the effect of Length on RT is "that big". But how can you statistically compare these in order to tell if one has a <em>significantly</em> bigger effect than than the other?</p>
		<p class="centercol">The code below is an attempt to solve that problem. The general approach (treating it as a <em>t</em>-test, by taking the difference between coefficients divided by their pooled variance) is something that was suggested to me by someone at my campus's stats help center at the time, and the rest of the details here are just tweaks I've added on over the years. For a long time I've just had this code floating around in an e-mail from like 15 years ago that I dig up again whenever someone asks me about it. But with each passing year it gets harder and harder for me to remember how to find it, so I decided to finally write this down so I [hopefully?] won't lose it. And if it ends up being useful for someone else in the world, too, then that's an added bonus. But use it at your own risk since it's essentially just nonsense I made up when I was a grad student.</p>


		<h3>The code</h3>
		<p class="centercol">The following function will calculate the t-statistic for a comparison between two coefficients in a linear model (such as the kind you get from the <code>lm()</code> function):</p>
<p class="centercol" style="border:1px solid #000; border-style: dotted; padding:10px; background-color: white;"><code>compare_coefs <- function( model, coef1, coef2 ){<br /><br />diff <- (coef(model)[coef1] - coef(model)[coef2])<br />pooledvar <- sqrt( vcov(model)[coef1,coef1] + vcov(model)[coef2,coef2] - 2*vcov(model)[coef1,coef2] )<br />t <- diff / pooledvar<br />names(t) <- NULL # this is just for cosmetic purposes, it doesn't actually matter<br />return(t)<br /><br />}</code></p>
		<p class="centercol">To use it, just give it your model, plus the names or indices of the coefficients you want to compare. For example:</p>
<p class="centercol" style="border:1px solid #000; border-style: dotted; padding:10px; background-color: white;"><code>m <- lm( Temp ~ Wind + Ozone, airquality )<br />compare_coefs( m, 2, 3) # Compare the 2nd and 3rd coefficient<br />compare_coefs( m, "Wind", "Ozone" ) # Compare the "Wind" and "Ozone" coefficients; should get the same value</code></p>
		<p class="centercol">This will give you a <em>t</em>-statistic for the difference between those two coefficients. From there, you can just calculate the <em>p</em>-value of this statistic based on the degrees of freedom (which you can normally steal from the model summary):</p>
<p class="centercol" style="border:1px solid #000; border-style: dotted; padding:10px; background-color: white;"><code>t <- compare_coefs( m, "Wind", "Ozone" )<br />df <- m$df.residual # summary(m) shows that this is 113<br />pt( -abs(t), df ) *2 # I use -abs() to force t to be negative, and *2 to get a two-tailed p-value )</code></p>

 		<h3>Mixed-effects models</h3>
		<p class="centercol">If you want to do this to compare coefficients in a mixed-effects model, you'll have to make a few adjustments. In all the following, I am assuming you are using the <code>{lme4}</code> package to make your models. Use this at your own risk; it will give you numbers, and I <em>think</em> those numbers are accurate and actually mean something, but that's really a question for a statistician.</p>
		<p class="centercol">First, in the code, replace the <code>coef()</code> function with <code>fixef()</code> This is just necessary because lme4 models store the coefficients we want [in the format that I have lazily hard-coded the function to expect] in a structure that is accessed by <code>fixef()</code> rather than <code>coef()</code>.</p>
<p class="centercol" style="border:1px solid #000; border-style: dotted; padding:10px; background-color: white;"><code>compare_coefs <- function( model, coef1, coef2 ){<br /><br />diff <- (fixef(model)[coef1] - fixef(model)[coef2])<br />pooledvar <- sqrt( vcov(model)[coef1,coef1] + vcov(model)[coef2,coef2] - 2*vcov(model)[coef1,coef2] )<br />t <- diff / pooledvar<br />names(t) <- NULL # this is just for cosmetic purposes, it doesn't actually matter<br />return(t)<br /><br />}<br /><br /># Example:<br />library(languageR)<br />library(lme4)<br />m <- lmer( RT ~ Frequency + FamilySize + (1|Subject) + (1|Word), lexdec ) # using intercept-only models for this demo so the code runs fast; plz don't use intercept-only models for real<br />compare_coefs( m, "Frequency", "FamilySize" )</code></p>
	<p class="centercol">Secondly, if you want to turn the <em>t</em>-statistic into a <em>p</em>-value, things are a bit more complicated. <code>summary(model)</code> or <code>model$df.resid</code> won't tell you degrees of freedom for an lme4 model like it did for a straight-up lm model. How to calculate degrees of freedom for a mixed-effects model is actually a controversial, hot-button issue in the exciting and glamorous world of statistics. The good news for us, however, is that <a href="https://link.springer.com/article/10.3758/s13428-016-0809-y">Luke (2017)</a> gives us permission to just use degree-of-freedom estimates from <code>lmerTest</code> and be done with it. (Apologies to Luke for my massively oversimplified summary of a very detailed paper.) So that's what I'd recommend doing. Load up <code>{lmerTest}</code> before you do your model, so that <code>summary()</code> will give you dfs, and just shamelessly steal that number to put into your bit that calculates the <em>p</em>-value.</p>

	<h3>Other considerations</h3>
	<p class="centercol"><strong>Comparing magnitudes regardless of sign.</strong> Depending on the research question you are trying to address when doing this analysis, you might actually want to compare the absolute values of two coefficients, rather than the coefficients themselves. For example, imagine that you've got some data where predictor A has an association of "5" with the outcome variable, and predictor B has an association of "-5". These might turn out to be significantly different from one another (5 is ten whole units bigger than -5!). But the magnitude of these associations are the same. If that's what you care about, you can easily adapt the above code by just putting <code>abs()</code> around each coefficient:</p>
<p class="centercol" style="border:1px solid #000; border-style: dotted; padding:10px; background-color: white;"><code>compare_coefs <- function( model, coef1, coef2 ){<br /><br />diff <- (abs(coef(model)[coef1]) - abs(coef(model)[coef2]))<br />pooledvar <- sqrt( vcov(model)[coef1,coef1] + vcov(model)[coef2,coef2] - 2*vcov(model)[coef1,coef2] )<br />t <- diff / pooledvar<br />names(t) <- NULL # this is just for cosmetic purposes, it doesn't actually matter<br />return(t)<br /><br />}</code></p>

	<p class="centercol"><strong>Comparing variance instead of magnitude.</strong> This is a tricky one. Imagine that the coefficient for predictor A is 5, with a standard error of 1; and the coefficient for predictor B is also 5, but with a standard error of 10. Predictor A clearly has a "stronger" association with the outcome. But the code I've provided here won't tell you that predictor A is significantly better than predictor B; to the contrary, you're going to get a <em>t</em>-statistic of 0. I don't know what test you'd need to run to compare the "strengths" of association in the way. It should be doable (rather than directly comparing the coefficients, I'm guessing you'd want to compare the coefficients' <em>t</em>-statistics; and meta-analysis people have ways of doing that kind of thing) but the code on this page doesn't do it.</p>

	<p class="centercol"><strong><em>df</em>s in generalized linear models</strong>. My suggestions above for calculating <em>p</em>-values are based on using degrees of freedom. If you use a generalized model (like <code>glm</code> or <code>glmer</code>), you won't see degrees of freedom. Since coefficients in those models can be tested with a <em>z</em> distribution, I just ignore degrees of freedom for this and calculate <em>p</em> based on a z distribution rather than a t distribution. Am I allowed to do that? Not sure! That's another question for a statistician!</p>

	<hr>
	<p class="mini">by <a href="./">Stephen Politzer-Ahles</a>. Last modified on 2025-02-13.</p>



    </body>
</html>
