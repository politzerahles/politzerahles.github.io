<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "DTD/xhtml1-transitional.dtd">
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
        <title>Stephen Politzer-Ahles</title>
        <link rel="stylesheet" type="text/css" href="stevetools_stylesheet.css" />
    </head>

    <body style="background:#DCDCDC">
        <div id="top">

            <table border="0" width="60%" align="center">
                <tr>
			<td style="padding:5% 5% 5% 0%" ><a href="https://en.wikipedia.org/wiki/Panipuri"><img src="panipuri.jpg" width=100% title="Panipuri (&#x092A;&#x093E;&#x0928;&#x0940; &#x092A;&#x0942;&#x0930;&#x0940;)" alt="" /></a></td>
			<td align="center">
			<h2>Stephen Politzer-Ahles</h2>
			<h4>University of Kansas</h4>
			<p>sjpa&nbsp;&#x55BA;&nbsp;ku&nbsp;&#x9EDE;&nbsp;edu</p>
 			</td>
                </tr>
            </table>
        </div>


        
	<div id="vert_tabs" style="float:left;">
		<ul>
			<li><a href="." title="About me">About (and CV)</a></li>
			<li><a href="./Classes/" title="Classes">Classes</a></li>
			<li id="selected"><a href="papers.html" title="Published papers">Papers</a></li>
			<li><a href="presentations.html"  title="Posters and talks">Posters and talks</a></li>
			<li><a href="union.html" title="Union work">Union work</a></li>
			<li><a href="filedrawer.html" title="Writeups of unpublished work that's gone to the file drawer">File drawer</a></li>
			<li><a href="webstuff.html" title="Blog posts and other online public outreach">Fun Internet stuff</a></li>
			<li><a href="programs.html" title="Useful tools for linguistic stuff">Hopefully useful stuff</a></li>
		</ul>
	</div>

	<div id="main">		                    
		 <h3 class="centercol">Peer-reviewed journal articles</h3>
			<p class="centercol" style="font-size: 0.75em;">* indicates <a href="https://www.cos.io/initiatives/registered-reports">registered reports</a></p>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">*Bernard Jap, Yu-Yin Hsu, &amp; Stephen Politzer-Ahles (in press). <strong>Neural correlates of thematic role assignment for passives in Standard Indonesian</strong>. <em>PLoS ONE</em>.</summary><p style="background-color: white; padding: 2em">Several decades' worth of studies have shown that sentences in the passive voice elicit a different pattern of brain activity than sentences in the active voice. It has never been clear, though, whether this happens because passive-voice sentences are structurally more complex than active-voice sentences, or because they're less common. In a language like English, those things both happen to be true, so how can we disentangle them? Well, it turns out that in Indonesian, passive voice is used much more often than in English, such that its frequency is much closer to that of active voice. In this registered report, Bernard took advantage of that fact to try to answer that longstanding conundrum. It turned out that Indonesian passive-voice sentences still elicit different brain activity than active-voice sentences, which suggests that this difference is triggered by the syntactic structure of passive voice, not by how common or uncommon it is.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Jennifer Lewendon, James Britton, &amp; Stephen Politzer-Ahles (2024). <strong>The Phonological Mapping Negativity (PMN) as a language-specific component: exploring responses to linguistic vs musical mismatch</strong>. <em>PLoS ONE, 19</em>,  e0315537. [<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0315537">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">When people are expecting one word and then hear a word that differs by one sound (e.g., hearing <em>lap</em> when they expected <em>map</em>), they show a particular pattern of brain activity, called the Phonological Mapping Negativity, or PMN for short. This pattern has long been argued to be specific to <em>language</em>-related mismatches. but there was actually little empirical test of that assumption. In this study, Jen systematically tested that assumption, by comparing people's brain responses to linguistic mismatches versus to musical mismatches. We found that the PMN effect indeed only occurred for linguistic mismatches, not for musical mismatches.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Bernard Jap, Stephen Politzer-Ahles, &amp; Yu-Yin Hsu (2024). <strong>Are cleft sentence structures more difficult to process?</strong> <em>Neuroscience Letters, 843</em>, 138029. [<a href="https://www.sciencedirect.com/science/article/pii/S0304394024004087">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">*Stephen Politzer-Ahles &amp; Bernard Jap (2024). <strong>Can the mismatch negativity really be elicited by abstract linguistic contrasts?</strong> <em>Neurobiology of Language, 5</em>, 818-843. [<a href="https://direct.mit.edu/nol/article/doi/10.1162/nol_a_00147/121672/Can-the-mismatch-negativity-really-be-elicited-by">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The <em>mismatch negativity</em> is a brain response that occurs when a person subconsciously detects a difference between two categories of stimuli (as in, for instance, <em>ba ba ba ba ba ba <strong>pa</strong></em>). It has long been thought to be an index of the brain's detection of any changes, including differences between abstract categories. That explanation had not been strongly put to the test, however, because almost all previous studies involved situations in which the difference between categories can be recognized based on some kind of physical cue. This study tested for abstract change detection by presenting listeners with purely abstract linguistic contrasts with no reliable physical cue: the difference between past-tense and present-tense verbs (as in, e.g., <em>chose sang bled swore clung <strong>pave</strong></em>). Amazingly, the brain still detected this sort of abstract contrast&mdash;even with no physical correlate, and even without listeners actively paying attention to these streams of stimuli. This provides the strongest evidence to date that the mismatch negativity really is an index of the brain's automatic detection of differences between abstract categories of stimuli.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Roman Sarrazin-Gendron, Parham Ghasemloo Gheidari, Alexander Butyaev, Timothy Keding, Eddie Cai, Jiayue Zheng, ..., Borderlands Science players, ..., &amp; Jérôme Waldispühl (2024). Improving microbial phylogeny with citizen science within a mass-market video game. <em>Nature Biotechnology</em>.</summary><p style="background-color: white; padding: 2em">Ok, now this one is just a little bit of fun. I'm not really an author on it in any proper sense; I'm more like a participant.<br /><br />What <a href="https://www.nature.com/articles/s41587-024-02175-6">the paper</a> describes is a "citizen science" exercise. The authors had a DNA data problem that was computationally intractable for computers, so instead they "gamified" it into a puzzle game, "Borderlands Science", which they embedded within the popular looter-shooter video game <em>Borderlands 3</em>. Over the next few years, about 4 million people played "Borderlands Science", contributing a ton of puzzle solutions which led to actual breakthoughs in the processing of those DNA data. This paper describes that process, and how the approach can be used for other "citizen science" research endeavors. The authors generously listed "Borderlands Science players" as coauthors, and I am one of those 4 million people who played the game, so I'm sort of a coauthor on this paper. But I didn't make any contribution other playing a bunch of Borderlands Science (and enjoying some of that sweet sweet XP), so I'm really more of a participant than an author. But it's a super cool project and I'm so happy that I was a small (like 1/4,000,000th) part of it.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Wenting Xue, Meichun Liu, Stephen Politzer-Ahles, & Ovid Jyh-Lang Tzeng (2024). <strong>Verbal effect on the processing of complement coercion: distinguishing between aspectual verbs and psych verbs</strong>. <em>Lingua, 306</em>, 103754. [<a href="pubs/Xueetal_2024_Lingua.pdf">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Jennifer Lewendon, Stephen Politzer-Ahles, & James Britton (2023). <strong>The MMN by another name? Exploring the autonomy of the Phonological Mapping (Mismatch) Negativity</strong>. <em>Language, Cognition and Neuroscience, 38</em>, 1098-1114. [<a href="pubs/Lewendonetal2023.pdf">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles, Lei Pan, Jueyao Lin, & Ka Keung Lee (2023). <strong>Long-lag identity priming in the absence of long-lag morphological priming: evidence from Mandarin tone alternation</strong>. <em>Glossa: Psycholinguistics, 2</em>, 2. [<a href="https://escholarship.org/uc/item/96k7g38p">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"> (Old versions: <a href="pubs/Politzer-Ahlesetal_hisphoncog2018_priming.pdf">poster 1</a>, <a href="pubs/Politzer-Ahlesetal_labphon2018.pdf">poster 2</a>, <a href="pubs/Politzer-Ahlesetal_HISPhonCog2019.pdf">poster 3</a>, <a href="pubs/Politzer-Ahlesetal_amlap2018.pdf">slides</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Yao Yao, Katrina Connell, & Stephen Politzer-Ahles (2023). <strong>Hearing emotion in two languages: a pupillometry study of Cantonese-Mandarin bilinguals' perception of affective cognates in L1 and L2</strong>. <em>Bilingualism: Language and Cognition, 26</em>, 795-808. [<a href="https://www.cambridge.org/core/journals/bilingualism-language-and-cognition/article/hearing-emotion-in-two-languages-a-pupillometry-study-of-cantonesemandarin-bilinguals-perception-of-affective-cognates-in-l1-and-l2/EF231BE13AAFB65F07E96475D0B822F3">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Xiaocong Chen, Caicai Zhang, Yiya Chen, Stephen Politzer-Ahles, Yuyu Zeng, & Jie Zhang (2022). <strong>Encoding category-level and context-specific phonological information at different stages: an EEG study of Mandarin third-tone sandhi word production</strong>. <em>Neuropsychologia, 175</em>, 108367. [<a href="https://www.sciencedirect.com/science/article/pii/S0028393222002263">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Jie Zhang, Caicai Zhang, Stephen Politzer-Ahles, Ziyi Pan, Xunan Huang, Chang Wang, Gang Peng, & Yuyu Zeng (2022). <strong>The neural encoding of productive phonological alternation in speech production: Evidence from Mandarin Tone 3 sandhi</strong>. <em>Journal of Neurolinguistics, 62</em>, 101060. [<a href="https://www.sciencedirect.com/science/article/pii/S0911604422000045">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Teresa Girolamo, Stephen Politzer-Ahles, Samantha Ghali, & Brittany Williams (2022). <strong>Preliminary evaluation of applicants to master's programs in speech-language pathology using vignettes and criteria from a holistic review process</strong>. <em>American Journal of Speech-Language Pathology, 31</em>, 552-577. [<a href="pubs/AJSLP-20-00352_R2 copy.pdf">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles, Jueyao Lin, Lei Pan, & Ka Keung Lee (2022). <strong>N400 evidence that the early stages of lexical access ignore knowledge of phonological alternations</strong>. <em>Language and Speech, 65</em>, 354-376. [<a href="https://journals.sagepub.com/doi/full/10.1177/00238309211020026">full&nbsp;text]</summary><p style="background-color: white; padding: 2em">(Old versions: <a href="pubs/Politzer-Ahlesetal_hisphoncog2018_eeg.pdf">slides 1</a>, <a href="pubs/Politzer-Ahlesetal_NYUAD2019.pdf">slides 2</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Mehdi Bakhtiar, Maryam Mokhlesin, Chotiga Pattamadilok, Stephen Politzer-Ahles, & Caicai Zhang (2021). <strong>The effect of orthographic transparency on auditory word recognition across the development of reading proficiency</strong>. <em>Frontiers in Psychology, 12</em>, 3129. [<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.691989/full">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Wenting Xue, Meichun Liu, & Stephen Politzer-Ahles (2021). <strong>Processing of complement coercion with aspectual verbs in Mandarin Chinese: evidence from a self-paced reading study</strong>. <em>Frontiers in Psychology, 12</em>, 1973. [<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.643571/full">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em"></p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles & Suyeon Im (2020). <strong>Mismatch negativity is not always modulated by lexicality</strong>. <em>Frontiers in Human Neuroscience, 14</em>, 459. [<a href="https://www.frontiersin.org/articles/10.3389/fnhum.2020.556457/full">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">Since the early 2000s, a particular component of brainwave activity was thought to be particularly sensitive to real words. This component is a part of the brainwave called the mismatch negativity, and some studies from that time had seemed to show that real words elicit a bigger mismatch negativity than fake words. In this paper, however, we report two high-power studies showing that this is actually not the case; in our two studies, with a far larger sample size than any previous one, real words did not elicit larger mismatch negativities than fake words. In this paper we also provided a more comprehensive review of the literature, showing that there were actually multiple other previous experiments failing to find this difference. (Old versions: <a href="pubs/Politzer-AhlesIm_HISPhonCog2019.pdf">slides</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles (2020). <strong>What can electrophysiology tell us about the cognitive processing of scalar implicatures?</strong> <em>Language and Linguistics Compass, 14</em>, 1-22. [<a href="https://onlinelibrary.wiley.com/doi/10.1111/lnc3.12401">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">This is not a empirical paper (i.e., not a paper presenting new results from some experiment), but rather is a literature review: a paper that attempts to tie together a bunch of different research to hopefully synthesize some new insights or conclusions. In particular, this paper takes up the growing body of research that has been using brainwave research to study how we "read between the lines" to determine what certain expressions are intended to mean. This sort of "between-the-lines" meaning is called <em>pragmatic</em> meaning in linguistics. While much of that research had taken the perspective of trying to find the "neural correlates" of pragmatics, this paper argues that much of the previous research (including my own) can't actually identify neural correlates of pragmatics. The paper wraps up by suggesting some different experiment design approaches that can be used to more effectively tackle that question, and highlights a few model examples of that kind of research. (Old versions: <a href="pubs/Politzer-Ahles2017_bochumworkshop.pdf">slides</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles, Teresa Girolamo, & Samantha Ghali (2020). <strong>Preliminary evidence of linguistic bias in academic reviewing</strong>. <em>Journal of English for Academic Purposes, 47</em>, 100895. [<a href="https://www.sciencedirect.com/science/article/pii/S1475158520301685">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">For a few years before this paper came out, a debate had been raging over whether there's a such thing as "linguistic injustice" in academic publishing&mdash;specifically, whether writers of scholarly work have a more difficult time of it if their first language is not English. (I should also acknowledge here that I bear some of the responsibility for starting this debate to begin with, specifically because of Politzer-Ahles et al. 2016 in <em>Journal of Second Language Writing</em>.)The debate was kind of intractable because arguments in favor of the existence of linguistic injustice were based on speculation (like "here are reasons that it must be hard, right?") or on self-report (like "I had a hard time of it") or other methods that left a lot of confounds. What we did in this study was the first-ever blinded randomized-control-trial sort of study to show that scholarly work written in "non-native"-sounding English get judged as being less "scientific", even when its scientific content is identical to work written in "native"-sounding English. This makes it the first study to provide hard evidence that [one particular source of] linguistic injustice really exists.<br /><br />Since the advent of generative AI, there have been more and more papers saying something along the lines of "generative AI can help reduce linguistic injustice by helping people proofread their papers" and then citing <em>this</em> paper. I do not endorse that and I don't think our paper ever expressed such a position; while we didn't say much in the way of recommendations, what little we did say was squarely focused on how linguistic injustice should be reduced by <em>reducing reviewers' biases</em> (since reviewer bias is what this paper was actually about). We never recommended that it should be scholar-writers' own responsibility to use any tools to make their writing better conform to a certain variety of English, and I regret that we didn't make that clearer.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles, Ka Keung Lee, & Lue Shen (2020). <strong>Ganong effects for frequency may not be robust</strong>. <em>JASA Express Letters, 147</em>, EL37-EL42. [<a href="https://asa.scitation.org/doi/10.1121/10.0000562">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">When people hear an ambiguous sound, the way they ultimately interpet it is affected by context. For example, if you take a sound that's halfway between a [d] and a [t], people will be more likely to interpret it as a [t] if you put it in the context <em>_ask</em> (where [t] makes a real word "task") than if you put that exact same sound in the context <em>_esk</em> (where [t] makes a fake word *"tesk"). This paper reports an experiment in which we tried to see if the same effect would happen with contexts that make a common vs. an uncommon word; for example, would people be more likely to interpret this sound as [t] in <em>_ime</em> (where "time" is more common than "dime") and less likely to interpret it as [t] in <em>_or</em> (where "tore" is less common than "door")? It turns out that they're not: people's judgments of ambiguous sounds were influenced by whether the context makes a real word or a fake word, but <em>not</em> by whether the context makes a common or uncommon word. (Old versions: <a href="pubs/Politzer-AhlesLee_HISPhonCog2019.pdf">poster 1</a>, <a href="pubs/ShenPolitzer-Ahles_hisphoncog2018.pdf">poster 2</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Se&#x00E1;n Roberts, Christine Cuskley, Stephen Politzer-Ahles, & Tessa Verhoef (2020). <strong>Double-blind reviewing and gender biases at EvoLang conferences: an update</strong>. <em>Journal of Language Evolution, 5</em>, 92-99. [<a href="pubs/Robertsetal2020EvoLang.pdf">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">This is a neat project that I only contributed a little bit to but am very fortunate to have had the opportunity to be a part of. Se&#x00E1;n Roberts had previously done an analysis of submissions to a major conference on language evolution, and had found evidence that there was potential gender bias before (with abstracts written by women getting lower ratings than they perhaps should have gotten) but that this effect was mitigated when the conference switched to double-blind reviewing. In this new paper, Se&#x00E1;n added data from the [then] latest iteration of the conference, to see how the situation had changed since his previous paper had made the field aware of this issue. The pattern is quite interesting. The fascinating details are in the paper, but the short version is: the pattern of data suggests (or at least is not inconsistent with the possibility) that the experience of having double-blind reviewing at the previous year's conference led authors to change how they wrote their abstracts in the following year.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">*Stephen Politzer-Ahles & Lei Pan (2019). <strong>Skilled musicians are indeed subject to the McGurk effect</strong>. <em>Royal Society Open Science, 6</em>, 181868. 
[<a href="https://royalsocietypublishing.org/doi/10.1098/rsos.181868">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The <a href="https://www.youtube.com/watch?v=aFPtc8BVdJk">McGurk effect</a> is a classic psycho-perceptual phenomenon: splice together a video of someone saying "ba" with audio of them saying "ga", and people will think the person is saying "da". A couple years before publishing this paper, Lei and I noticed a paper claiming that people with music experience are not susceptible to this perceptual illusion. We had some concerns with the data and statistical analysis being used to make that claim, and at the time Lei had just finished a psycholinguistics class and wanted more, so we decided to do our own replication of that study. We found that, contrary to the original study, musicians <em>do</em> still get the McGurk effect, and they do so just as much as everyone else.<br /><br />This paper also happens to be my first ever <em>registered report</em>. Registered reports are a special new way of publishing academic research. In the traditional way, you spend a long time doing some research and writing up a paper, then it goes out to reviewers, and it might get accepted for publication or the reviewers might be like "actually you were doing X Y and Z wrong all along, go redo it before it's publishable". In a <em>registered report</em>, on the other hand, you first send out your experiment plan to reviewers before actually doing the experiment, and they give you all that constructive criticism before you spend time actually doing the experiment. That way, once you actually start doing the experiment, you're doing something that's been carefully vetted and is guaranteed to be published, regardless of how the results come out (as long as you follow the plan that was vetted). This both saves researchers the time they would have otherwise spent doing experiments that might have had problems, and also removes the pressure to massage your data to make it look "publishable".</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Mante Nieuwland, Dale Barr, Federica Bartolozzi, Simon Busch-Moreno, Emily Darley, David Donaldson, Heather Ferguson, Xiao Fu, Evelien Heyselaar, Falk Huettig, E. Matthew Husband, Aine Ito, Nina Kazanina, Vita Kogan, Zdenko Koh&#x00FA;t, Eugenia Kulakova, Diane M&#x00E9;zi&#x00E8;re, Stephen Politzer-Ahles, Guillaume Rousselet, Shirley-Ann Rueschemeyer, Katrien Segaert, Jyrki Tuomainen, Sarah Von Grebmer Zu Wolfsthurn (2019). <strong>Dissociable effects of prediction and integration during language comprehension: evidence from a large-scale study using brain potentials</strong>. <em>Philosophical Transactions B, 375</em>, 20180522. [<a href="https://royalsocietypublishing.org/doi/10.1098/rstb.2018.0522">full&nbsp;text</a>] </summary><p style="background-color: white; padding: 2em">This paper is sort a companion piece to Mante Nieuwland's multi-lab study (Nieuwland et al., 2018) discussed a few entries below. We used the data from that same experiment (it was such a massive undertaking, it would be a shame not to do lots with those data) and did some additional analysis of the data to answer new questions. Specifically, we found that the N400, which is often talked about as if it's one brainwave, actually represents multiple sub-components. Using fancy schmancy statistical analysis on this huge and well-controlled dataset, Mante was able to show that how predictable a word is in the context of a sentence and how plausibly the word fits in the sentence actually have two different, albeit overlapping, effects on the brain signal; it just takes fancy stats and tons of data to disentangle these effects. (<a href="https://www.biorxiv.org/content/early/2019/01/08/267815">preprint</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">I-Hsuan Chen, Stephen Politzer-Ahles, & Chu-Ren Huang (2018). <strong>Determining the types of contrasts: the influence of prosody on pragmatic inferences</strong>. <em>Frontiers in Psychology, 9</em>, 2110. [<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02110/full">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">If someone says, "I didn't even see one cat", that means they didn't see one cat <em>as opposed to</em>... what, exactly? I didn't see one cat, let alone ten cats? Or I didn't see one cat, let alone one lion? One of these interpretations may make more or less sense depending on the context, of course. But where you place the stress also matters; "I didn't even see <em>ONE</em> cat" encourages a different interpretation than "I didn't even see one <em>CAT</em>". In the series of experiments described in this paper, I-Hsuan and I demonstrated quantitatively that changing the stress does indeed change which interpretation people say they got out of these kinds of sentences.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles & Page Piccinini (2018). <strong>On visualizing phonetic data from repeated measures experiments with multiple random effects</strong>. <em>Journal of Phonetics, 70</em>, 56-69. [<a href="https://www.sciencedirect.com/science/article/pii/S0095447017301407">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">This is not an empirical study (i.e., it's not reporting new findings from some experiment). Rather, it's a primer about how to create data visualizations and what sort of considerations to take into account when deciding how to visualize data. The most important part, I think, is one of the early figures, which demonstrates that a pair of condition means with error bars on them actually provides no information about whether two conditions are significantly different or not, if the conditions were manipulated in a repeated measures design. That sounds nitpicky if you're not a statistics person. But it was (and unfortunately still is) very common practice for people to assume two conditions are not significantly different because "their error bars cross", and that conclusion is not necessarily right&mdash;as our figure in this paper shows, two conditions can have almost completely overlapping error bars but still be statistically super-significanlty different. This paper was our little attempt to get people to switch to making graphs that actually illustrate the statistical comparisons they intend to make.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Mante Nieuwland, Stephen Politzer-Ahles, Katrien Segaert, Emily Darley, Nina Kazanina, Sarah Von Grebmer Zu Wolfsthurn, Federica Bartolozzi, Vita Kogan, Aine Ito, Diane M&#x00E9;zi&#x00E8;re, Dale J. Barr, Guillaume Rousselet, Heather J. Ferguson, Simon Busch-Moreno, Xiao Fu, Jyrki Tuomainen, Eugenia Kulakova, E. Matthew Husband, David I. Donaldson, Zdenko Koh&#x00FA;t, Shirley-Ann Rueschemeyer, Falk Huettig (2018). <strong>Large-scale replication study reveals a limit on probabilistic prediction in language comprehension</strong>. <em>eLife, 7</em>, e33468. [<a href="https://elifesciences.org/articles/33468">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">This paper represents a huge project, which was Mante Nieuwland's brainchild. He noticed that one of the classic and influential studies in neurolinguistics, on which much of our understanding of how prediction works in language is based, had actually almost never been replicated&mdash;which is not ideal, since replication is the gold standard of reliability in science. Given how important it was to replicate that study, he assembled a massive team of neurolinguistics across nine different laboratories to run simultaneous high-powered replications of that study, all while confirming to the highest standards of scientific replicability (e.g., pre-registration). The publication of this study sparked about huge surge of interest in neurolinguistic studies on prediction, and brought the issue of replicability to greater attention within the neurolinguistics community. (This study often gets described as failing to replicate the study on which it is based, but that's a bit of a mischaracterization. We actually did find a small effect consistent with what they found&mdash;albeit one that we only detected in exploratory analysis. But we also found that that effect was <em>so</em> small that it could only be meaningfully measured/studied in truly massive studies, bigger than anyone was or is doing, and so all the research done before couldn't tell the field much about the nature of this effect.) My role, other than running one of those nine experiments, was to set up some of the experiment software (used in about half of the labs) and help with running and reporting the statistical analysis. (Old versions: <a href="http://biorxiv.org/content/early/2017/02/25/111807">preprint</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles & E. Matthew Husband (2018). <strong>Eye movement evidence for context-sensitive derivation of scalar inferences</strong></a>. <em>Collabra: Psychology, 4</em>, 3. [<a href="http://doi.org/10.1525/collabra.100">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">One of my older studies (Politzer-Ahles & Fiorentino, 2013) had shown that, while interpreting <em>some</em> as meaning "not all" doesn't require any extra cognitive effort, it does depend on context: in some contexts we interpret <em>some</em> as "not all" and in some contexts we don't. Specifically, the old study showed that by showing that how we interpret <em>some</em> impacts how fast we recognize some other words later on (because interpreting <em>some</em> as "not all" will make us expect those words more). This study dug deeper into that finding by using eye-tracking, which gives much more fine-grained measures of how people read. It allowed us to pinpoint what stage of processing is impacted by people's interpretation of <em>some</em>; specifically, it's the early, predictive sort of processing. That provides further evidence that people really are computing different interpretations of <em>some</em> on the fly, and using those to predict upcoming words. (Old versions: <a href="pubs/Politzer-AhlesHusband2016_AMLaP.pdf">poster</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Kevin Schluter, Stephen Politzer-Ahles, Meera Al-Kaabi, & Diogo Almeida (2017). <strong>Laryngeal features are phonetically abstract: mismatch negativity evidence from Arabic, English, and Russian</strong>. <em>Frontiers in Psychology - Language Sciences, 8</em>, 746. [<a href="http://journal.frontiersin.org/article/10.3389/fpsyg.2017.00746/">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">Across a series of brainwave experiments in English, Arabic, and Russian, we found the same pattern of asymmetrical brain responses to sound contrasts. Specifically, the brains of listeners from all three of these language groups appear to treat voiced sounds like [z] as less "marked" than voiceless sounds like [s]&mdash;in other words, [s] is more different from [z] than [z] is from [s], in terms of how the brain reacts to the contrast between the two sounds. This happened regardless of how the sounds are physically realized (e.g., the difference between voiceless [s] and voiced [z] is physically quite different than the different between voiceless [t] and voiced [d]), and regardless of hwo the voiced-voiceless contrast is realized in the particular language (English is a language in which voiceless sounds are acoustically more "marked" than voiceless, whereas Arabic is the other way around, for example). This study, therefore, provided pretty compelling evidence that the way the brain responds to these contrasts is not purely based on their acoustics (how they physically sound), but on the abstract mental organization/structure of sounds.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Jiayu Zhan, Xiaoming Jiang, Stephen Politzer-Ahles, & Xiaolin Zhou (2017). <strong>Neural correlates of fine-grained meaning distinctions: an fMRI investigation of scalar quantifiers</strong>. <em>Human Brain Mapping, 8</em>, 3848-3864. [<a href="pubs/Zhanetal_HBM.pdf">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">This study used neuroimaging to examine what brain areas are involved both in interpreting <em>SOME</em> as meaning "not all", and also in interpreting <em>SOME</em> in meaning "not most". I only had a very small role in this study (mainly just providing some feedback on the idea and helping frame the arguments in the paper), but what I really like about it is that Jiayu managed to experimentally look at these two different interpretations of <em>SOME</em>. In the field of experimental pragmatics (research on how we "read between the lines" to figure out what things are intended to mean), everybody and their grandmother has been looking at <em>SOME</em>-as-not-all for decades, but hardly anyone did experiments on the other things that it means. (I had <a href="pubs/filedrawer/SI_most_SPR.html">tried something similar</a> some years before, but with less success than Jiayu's study here.)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles, Ming Xiang, & Diogo Almeida (2017). <strong>"Before" and "after": investigating the relationship between temporal connectives and chronological ordering using event-related potentials</strong>. <em>PLoS ONE, 12</em>, e0175199. [<a href="http://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0175199">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">Before this, a lot of studies had shown that sentences like "<em>Before this happened, that happened</em>" take a bit more cognitive effort to read than sentences like "<em>After that happened, this happened</em>". But it was never actually clear if this difference occurs because "<em>Before X, Y</em>" presents the events out of order (this is the explanation that pretty much all the previous research assumes), or because <em>before</em> is actually special and different than <em>after</em> (there are actually linguistically-motivated reasons to assume this; the semantics and pragmatics of <em>before</em> really are kind of different). Our study disentangled these, by trying out a different sentence structure: "<em>This happened before that</em>" vs. "<em>This happened after that</em>". We found that it's always the out-of-order sentences&mdash;regardless of whether they use "<em>before</em>"&mdash;that trigger extra processing costs. So in a way this study confirmed what the field had always assumed, but nobody had actually demonstrated that yet. (Old versions: <a href="pubs/Politzer-Ahlesetal_NLC2015.pdf">poster</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles (2017). <strong>An extension of within-subject confidence intervals to models with crossed random effects</strong>. <em>The Quantitative Methods for Psychology, 13</em>, 75-94. [<a href="http://www.tqmp.org/RegularArticles/vol13-1/p075/index.html">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">This paper proposes a new way to draw error bars on graphs so that they more accurately reflect which conditions are significantly different from which. Error bars representing traditional confidence intervals don't do that for data with repeated measures (e.g., comparing different conditions within the same individuals). Solutions for that situation have been around since the '90s (although they are still almost never used). But those solutions don't address the situation of having multiple kinds of repeated measures at once. This situation is very common in many research areas now&mdash;e.g., psycholinguistic research involves comparions different conditions within the same people <em>and</em> the same words. The method for calculating error bars described in this paper can handle this situation.<br /><br />For updated, better code, as well as an easier-to-follow worked example, see <a href="LMEMintervals.html">LMEM-based intervals for error bars in graphs</a>.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Stephen Politzer-Ahles, Kevin Schluter, Kefei Wu, & Diogo Almeida (2016). <strong>Asymmetries in the perception of Mandarin tones: evidence from mismatch negativity</strong>. <em>Journal of Experimental Psychology: Human Perception and Performance, 42</em>, 1547-1570. [<a href="http://psycnet.apa.org/journals/xhp/42/10/1547.html">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">Across three experiments, each comparing Mandarin-speaking vs. non-Mandarin-speaking volunteers, we found evidence that Mandarin "Tone 3" is processed differently in the brain than the other three tones in the language. More importantly, in the last experiment we found that some part of this difference is <em>not</em> due to physical aspects of how it sounds, but due to Mandarin speakers' abstract linguistic knowledge of the phonological properties of this tone.<br /><br />This was one of my favourite experiments to have ever been a part of doing, and one that I am the most proud of. One reason is because it was really a process of pursuing scientific discovery. The whole experiment came from a "failed" experiment (which I later followed up in Politzer-Ahles & Im, 2020), and we just kept doing experiment after experiment to figure out what had gone wrong in that "failed" experiment, ultimately leading to these new, important, and totally unexpected discoveries. Another fun thing about it is that Luck (2014:137), essentially the brainwave bible, describes a hypothetical experiment like this (specifically, one testing the same manipulation on one group of participants who knows the language and one who does not) as being the best kind of experiment design but one that is extremely "difficult and time-consuming". I hadn't been aware of that tidbit until some years after doing the experiment, but knowing that we unwittingly did an experiment that even Steve Luck would approve of makes me feel warm inside. (Old versions: <a href="pubs/Politzer-Ahles2015_CNS.pdf">poster 1</a>, <a href="pubs/Politzer-Ahlesetal_ASA2015poster.pdf">poster 2</a>, <a href="pubs/Politzer-Ahlesetal_ICPhS2015slides.pdf">slides</a>, <a href="https://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2015/Papers/ICPHS0380.pdf">proceedings paper</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Kevin Schluter, Stephen Politzer-Ahles, & Diogo Almeida (2016). <strong>No place for /h/: ERP investigation of English fricative place features</strong>. <em>Language, Cognition and Neuroscience, 31</em>, 728-740. [<a href="http://www.tandfonline.com/doi/full/10.1080/23273798.2016.1151058">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The first in a series of papers that Kevin, Diogo and I did on MMN asymmetries. This topic is ridiculously complicated but the short version is, the brain seems to register certain sound contrasts as being more "different" if you hear one then the other, but less different if you hear them the other way around. In this case, it was that [f]-[s] gets registered as a bigger "difference" than [s]-[f], but [h]-[s] vs. [s]-[h] show no such asymmetry. The reason this weird thing is surprisingly important is because it actually provides brain-level evidence for a particular theory of how the features of sounds are abstractly represented in the mind. (Old versions: <a href="pubs/Schluteretal_mfm2014.pdf">poster</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em">Robert Fiorentino, Stephen Politzer-Ahles, Natalie Pak, Mar&#x00ED;a Teresa Mart&#x00ED;nez-Garc&#x00ED;a, & Caitlin Coughlin (2015). <strong>Dissociating morphological and form priming with novel complex word primes: evidence from masked priming, overt priming, and event-related potentials</strong>. <em>The Mental Lexicon, 10</em>, 413-434. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5683718/">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The experiments in this paper examined how people break down made-up compound words (like <em>drugrack</em>&mdash;not a real word, but made by combining two real words) as opposed to made-up words that aren't even compounds (like <em>slegrack</em>). For reasons that the paper gets into, these are a really good testing ground for the longstanding question of whether and how the mind breaks words down into their parts when we read or hear them. The experiment provided new (at the time) evidence that our minds really do attempt to break words down into all their possible parts when we see them.</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em"><a name="LCN2015"></a>Stephen Politzer-Ahles & Laura Gwilliams (2015). <strong>Involvement of prefrontal cortex in scalar implicatures: evidence from magnetoencephalography</strong>. <em>Language, Cognition and Neuroscience, 30</em>, 853-866. [<a href="http://www.tandfonline.com/doi/full/10.1080/23273798.2015.1027235">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The experiment described in this paper demonstrated that a certain portion of lateral prefrontal cortex is more active when it's hard to interpret <em>some</em> as meaning "not all" (i.e., when there is little contextual support for it) than when it's easy to. This was actually quite striking, because traditional theories of this sort of meaning processing had assumed that if there is any computational effort involved in realizing that "not all" meaning then it would be all-or-nothing (i.e., when you interpret <em>some</em> as meaning "not all" you work hard for it, and when you don't you don't). This study showed instead that that same computation can be hard or easy depending on how much contextual support there is. That finding is most consistent with a theory of processing that Judith Degen had recently proposed (which we discuss in more detail in the paper). Another thing I find important about this paper is a few paragraphs in the introduction which talk about experimental issues and confounds that need to be ruled out before you can conclude that an experiment really shows that implicatures (e.g., interpretations of <em>some</em> as meaning "not all") are hard to derive. Unfortunately, many (but not all!) studies since then have still made such claims without addressing those confounds. (Old versions: <a href="pubs/Politzer-Ahles2014_CUNY.pdf">poster</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em"><a name="JCL2015"></a>Stephen Politzer-Ahles & Jie Zhang (in press). <strong>Evidence for the role of tone sandhi in Mandarin speech production</strong>. <em>Journal of Chinese Linguistics Monograph Series</em>. [<a href="pubs/Politzer-AhlesZhang_2014_JCL.pdf">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The experiments in this paper used a funky 1970s psychological paradigm called "implicit priming" to demonstrate that, when people go to articulate a word, they use mental representations of not only the word's underlying form (how it's actually stored in the mind) but also its surface form (how it's pronounced in a certain context). This shows that pronunciation-changes-in-context aren't just something that happens in the mouth, but something that actually is programmed for in the mind before the initiation of articulation.<br /><br />But to be honest, the most interesting thing about this paper is not its content, but its publication history. I presented this study at a conference in 2012, and the conference attendees were invited to later write up papers for a journal special issue. I did that, and after a few rounds of revision it was accepted for publication in 2014. Since then it seems like the editor was unable to wrangle revisions from all the other authors, one thing led to another, and the special issue never got published. So this paper has been "accepted for publication" since 2014 (so, for 11 years, as of my writing this in 2025) and probably will never actually be published. Several of my colleagues with other papers accepted for this issue withdrew them and published them elsewhere, but I never did with this one; since it's been cited a little, and is findable here and on other resources like the Internet Archive, hopefully it's "out there" enough to have done some good for the field, but I'm not really prepared to do any more with it. (Old versions: <a href="pubs/Politzer-AhlesZhang2012_TAL.pdf">proceedings paper</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em"><a name="PONE2013"></a>Stephen Politzer-Ahles & Robert Fiorentino (2013). <strong>The realization of scalar inferences: context sensitivity without processing cost</strong>. <em>PLoS ONE, 8</em>,  e63943. [<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0063943">full&nbsp;text</a>].</summary><p style="background-color: white; padding: 2em">The experiment in this paper used measurements of people's reading times to demonstrate that understanding <em>some</em> as meaning "not all" doesn't actually take extra time or effort, compared to understanding it as meaning "more than zero". This actually goes against a lot of previous research, which had argued that the "not all" meaning takes extra cognitive effort to realize, but which we argue had un-addressed confounds. The finding of this paper unfortunately remains pretty ignored; lots of current research still repeats the claim that pragmatic meanings (like the interpretation of <em>some</em> as meaning "not all") take extra cognitive effort, as if this claim is a done deal, even though this and several other studies since have contradicted that. From time to time (fortunately very rarely) this paper even gets cited together with a pile of other papers at the end of a sentence saying scalar implicatures are cognitively effortful, which is the opposite of what this paper claims. (Old versions: <a href="pubs/Politzer-AhlesFiorentino_CUNY2013.pdf">poster</a>)</p></details>

			<details class="centercol"><summary style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em"><a name="NSL2013"></a>Lamar Hunt III, Stephen Politzer-Ahles, Linzi Gibson, Utako Minai, & Robert Fiorentino (2013). <strong>Pragmatic inferences modulate N400 during sentence comprehension: evidence from picture-sentence verification</strong>. <em>Neuroscience Letters, 534</em>, 246-251. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4010220/">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The experiment in this paper used EEG to demonstrate that, when people are in the process of reading a sentence, their predictions about upcoming words aren't just driven by sentence structure and literal meaning, but are also driven by the <em>implied</em> meaning(s) of the unfolding sentence. Previous studies had been argued to have shown that, but they all had various confounds which made it impossible to tell if they were really showing that or showing something else. Lamar's study here controlled that issue better than any study had before, by presenting sentences in well-controlled picture contexts&mdash;a method which has since been used on lots of other research building off of this technique to investigate even more nuanced and fine-grained kinds of distinctions.</p></details>

			<details class="centercol"><summary  style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em"><a name="JPhon2013"></a>Hyunjung Lee, Stephen Politzer-Ahles, & Allard Jongman (2013). <strong>Speakers of tonal and non-tonal Korean dialects use different cue weightings in the perception of the three-way laryngeal stop contrast</strong>. <em>Journal of Phonetics, 41</em>, 117-32. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4188348/">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The experiment in this paper demonstrated that, when Korean speakers from Seoul and Kyungsang perceive the differences between Korean stop consonants like ㄱ/ㅋ/ㄲ, they rely on different cues to different extents&mdash;Seoul listeners rely on both aspiration and fundamental frequency in a complex trading relationship, whereas Kyungsang listeners rely less on fundamental frequency. It's actually a really important and impactful study, and the role I had in it was very small and is the weakest part of the study. (Like <a href="https://www.youtube.com/watch?v=lmke7G3ccjo">honeydew or Jared Leto</a>, I was the worst part of this thing that I was in.) Specifically, I helped with the statistics, and this was back before I knew how to do multilevel models (a.k.a. mixed-effects models), so I used a 1990s analysis. We managed to get it published, but a reviewer called it a "poor man's multilevel model", and that comment is what drove me to learn how to do multilevel models. (Old versions: <a href="pubs/Leeetal_ASA2012.pdf">poster</a>)</p></details>

			<details class="centercol"><summary  style="cursor: pointer; padding-left: 5px; padding-top: 0.5em; padding-bottom: 0.5em"><a name="BRES2013"></a>Stephen Politzer-Ahles, Robert Fiorentino, Xiaoming Jiang, & Xiaolin Zhou (2013). <strong>Distinct neural correlates for pragmatic and semantic meaning processing: an event-related potential investigation of scalar implicature processing using picture-sentence verification</strong>. <em>Brain Research, 1490</em>, 134-152. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4016559/">full&nbsp;text</a>]</summary><p style="background-color: white; padding: 2em">The experiments in this paper demonstrated that sentences which <em>imply</em> something false elicit different patterns of brain activity than sentences which literally <em>mean</em> something false. Note: since this came out, it has frequently been cited as evidence that the brain processes pragmatics (i.e., what things imply) differently from semantics (i.e., what things literally mean). I no longer believe this paper really supports that claim; see Politzer-Ahles (2020) for my own takedown of this paper. (Old versions: <a href="pubs/PolitzerAhlesetal_CNS2011.pdf">poster 1</a>, <a href="pubs/PolitzerAhlesetal_NLC2011.pdf">poster 2</a>, <a href="pubs/PolitzerAhlesetal_CNS2012.pdf">poster 3</a>, <a href="https://kuscholarworks.ku.edu/handle/1808/7847"</a>master's thesis</a>)</p></details>

		 <h3 class="centercol">Chapters</h3>
			<ul class="center">
				<li>Stephen Politzer-Ahles, Julie S., Chen, &amp; I-Hsuan Chen (in press). <strong><a href="pubs/CHAPTER 3.pdf">Is self-paced listening sensitive to downstream consequences of focus?</a></strong> In Ivanova, O., Nandi, A, &amp; Prasannanshu [eds.], <em>Psycholinguistic Approaches to the Study of Linguistic Structures: Language in the Mind</em>, Cambridge Scholars.</li>
				<li>Stephen Politzer-Ahles & Si Chen (2019). <a href="pubs/Politzer-AhlesChen_significance.pdf"><strong>Significance</strong></a>. <em>The SAGE Encyclopedia of Human Communication Sciences and Disorders.</em></li>
			</ul>

		 <h3 class="centercol">Letters/commentaries/errata</h3>
			<ul class="center">
				<li>Stephen Politzer-Ahles, Se&#x00E1;n Roberts, Christine Cuskley, & Tessa Verhoef (2019).  <a href="https://academic.oup.com/jole/article/4/2/140/5530896"><strong>Errata for Roberts & Verhoef (2016)</strong></a>. <em>Journal of Language Evolution, 4</em>, 140-141.</li>
				<li>Stephen Politzer-Ahles, Jeffrey J. Holliday, Teresa Girolamo, Maria Spychalska, & Kelly Harper Berkson (2016). <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5502761/"><strong>Is linguistic injustice a myth? A response to Hyland (2016).</strong></a> <em>Journal of Second Language Writing, 34</em>, 3-8.<!-- (<a href="pubs/Politzer-Ahlesetal2016_JSLW.pdf">AAM</a>)--></li>
			</ul>			

		 <h3 class="centercol">Manuscripts</h3>
			<ul class="center">
				<li>Stephen Politzer-Ahles, Katrina Connell, Lei Pan, & Yu-Yin Hsu (under revision). <a href="pubs/447184_Politzer-Ahles_Manuscript.PDF"><strong>Mandarin third tone sandhi may be incompletely neutralizing in perception as well as production</strong></a>.</li>
				<li>Stephen Politzer-Ahles, Wing Ki Ng, & Li Chong Shih (under revision). <a href="pubs/Politzer-Ahles Ng Shih.pdf"><strong>No significant loanword priming advantage in Cantonese-English bilinguals</strong></a>. <em>Lingua Sinica</em>.</li>
				<li>Stephen Politzer-Ahles & Si Chen (manuscript that won't be resubmitted anywhere because Sassenhagen & Alday published a very similar paper around the same time and it's just as good). <a href="pubs/Politzer-AhlesChen_brm.pdf"><strong>You don't need <em>t</em>- or <em>F</em>-tests to show that your groups are matched</strong></a>.<!-- <em>Behavior Research Methods</em>.--></li>
				<!--<li>Cheung, Candice Chi-Hang, Stephen Politzer-Ahles, Heeju Hwang, Ages Yuen-Man Tang, Man Tak Leung, & Tempo Po Yi Tang. (submitted). Understanding of literal and figurative language in preschool-aged Cantonese-speaking children with and without autism spectrum disorders. <em>Clinical Linguistics and Phonetics.</em></li>-->
			</ul>

		 <h3 class="centercol">Selected<!--<span style="color:blue;" title="Papers based on data which have since been published as journal articles are not listed here; see CV for full list."><sup>?</sup></span>--> working papers and proceedings papers</h3>
			<ul class="center">
				<li>Candice Chi-Hang Cheung, Stephen Politzer-Ahles, Heeju Hwang, Ronald Lung Yat Chui, Man Tak Leung, & Tempo Po Yi Tang. (2017). <a href="pubs/Cheungetal2017_CLP.pdf"><strong>Comprehension of presuppositions in school-age Cantonese-speaking children with and without autism spectrum disorders</strong></a>. <em>Clinical Linguistics and Phonetics, 31</em> (conference proceedings special issue), 557-572.</li>
				<li><a name="LSA2015"></a>Stephen Politzer-Ahles (2015). <a href="http://journals.linguisticsociety.org/proceedings/index.php/ExtendedAbs/article/view/2990"><strong>"Maybe" not all scalar implicatures are created equal</strong></a>. <i>LSA Extended Abstracts</i>. (<a href="pubs/Politzer-Ahles2015_LSAslides.pdf">slides</a>)</li>
				<li>Stephen Politzer-Ahles (2012). <a href="http://kuscholarworks.ku.edu/dspace/handle/1808/10493"><strong>Are intermediate levels of the scale used during online comprehension of scalar implicatures?</strong></a> <i>Kansas Working Papers in Linguistics, 33</i>, 1-15.</li>
				<li>Stephen Politzer-Ahles & Jie Zhang (2012b). <a href="http://asa.scitation.org/doi/abs/10.1121/1.4772715"><strong>The role of phonological alternation in speech production: Evidence from Mandarin tone sandhi</strong></a>. <em>Proceedings of Meetings on Acoustics, 18</em>, 060001.</li>
<!--				<li>Stephen Politzer-Ahles & Jie Zhang (2012a). The role of tone sandhi in speech production: evidence for phonological parsing. <i>Tonal Aspects of Languages 2012</i>. (see <a href="#JCL2015">Politzer-Ahles & Zhang, in press</a>)</li> -->
				<li>Stephen Politzer-Ahles (2011). <a href="http://kuscholarworks.ku.edu/dspace/handle/1808/8100"><strong>A Minimalist account of Uyghur genitives</strong></a>. <i>Kansas Working Papers in Linguistics, 32</i>, 106-119.</li>
			</ul>

		<h3 class="centercol">Dissertation</h3>
			<ul class="center">
				<li><a name="diss"></a>Stephen Politzer-Ahles (2013). <a href="http://kuscholarworks.ku.edu/dspace/handle/1808/12280"><strong><em>Psycholinguistic and neurolinguistic investigations of scalar implicature</em></strong></a>. Doctoral dissertation, University of Kansas.</li>
			</ul>
	</div>


		<!--<div align="center">
			<img src="panipuri.jpg" width=55% align="center">
		</div>-->


 

</html>
</body>
